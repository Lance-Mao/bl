{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "         id author     source content  \\\n100   89517    NaN  中国证券报?中证网     NaN   \n103   89514    NaN  中国证券报?中证网     NaN   \n997   88620    NaN        央广网     NaN   \n1273  88344    NaN        央广网     NaN   \n1282  88335    NaN        央广网     NaN   \n\n                                                feature  \\\n100   {\"type\":\"公司\",\"site\":\"中证网\",\"commentNum\":\"0\",\"jo...   \n103   {\"type\":\"公司\",\"site\":\"中证网\",\"commentNum\":\"0\",\"jo...   \n997   {\"type\":\"时事要闻\",\"site\":\"参考消息\",\"commentNum\":\"0\",...   \n1273  {\"type\":\"IT业界\",\"site\":\"参考消息\",\"commentNum\":\"0\",...   \n1282  {\"type\":\"IT业界\",\"site\":\"参考消息\",\"commentNum\":\"0\",...   \n\n                                 title  \\\n100       天和防务股东未来6个月内计划减持不超过480万股公司股份   \n103                    晶盛机电调整限制性股票回购价格   \n997              [主播不在家]第二季：主播陈亮体验垃圾清运   \n1273                LKK洛可可：想象力经济时代或已到来   \n1282  CES2017：京东发布两款叮咚智能音箱新品 开放Alpha平台   \n\n                                                    url  \n100   http://www.cs.com.cn/ssgs/gsxw/201706/t2017062...  \n103   http://www.cs.com.cn/ssgs/gsxw/201706/t2017062...  \n997   http://www.cankaoxiaoxi.com/china/20170623/214...  \n1273  http://www.cankaoxiaoxi.com/science/20170610/2...  \n1282  http://www.cankaoxiaoxi.com/science/20170610/2...  \n(87054, 7)\n",
      "(87054, 884)\n",
      "可疑文章数：3732\n",
      "[(63511, array([[0.94643198]])), (29441, array([[0.94283416]])), (980, array([[0.87535155]])), (29615, array([[0.86936328]])), (29888, array([[0.86215862]])), (64046, array([[0.85278235]])), (29777, array([[0.84875422]])), (63974, array([[0.73415212]])), (63975, array([[0.73415212]])), (64758, array([[0.73394798]]))]\n怀疑抄袭：\n 　　中国5月份56座城市新建商品住宅价格环比上涨，4月份为58座上涨。5月份15个一线和热点二线城市房地产市场基本稳定，5月份房地产调控政策效果继续显现。\r\n　　统计局：15个一线和热点二线城市房价同比涨幅全部回落\r\n　　国家统计局城市司高级统计师刘建伟解读5月份房价数据\r\n　　5月份一二线城市房价平均涨幅继续回落\r\n　　国家统计局今日发布了2017年5月份70个大中城市住宅销售价格统计数据。对此，国家统计局城市司高级统计师刘建伟进行了解读。\r\n　　一、15个一线和热点二线城市新建商品住宅价格同比涨幅全部回落、9个城市环比下降或持平\r\n　　5月份，因地制宜、因城施策的房地产调控政策效果继续显现，15个一线和热点二线城市房地产市场基本稳定。从同比看，15个城市新建商品住宅价格涨幅均比上月回落，回落幅度在0.5至6.4个百分点之间。从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅在0.5%以内。\r\n　　二、70个大中城市中一二线城市房价同比涨幅持续回落\r\n　　5月份，70个城市中新建商品住宅和二手住宅价格同比涨幅比上月回落的城市分别有29和18个。其中，一二线城市同比涨幅回落尤其明显。据测算，一线城市新建商品住宅和二手住宅价格同比涨幅均连续8个月回落，5月份比4月份分别回落2.2和1.7个百分点；二线城市新建商品住宅和二手住宅价格同比涨幅分别连续6个月和4个月回落，5月份比4月份分别回落0.8和0.5个百分点。\r\n　　三、70个大中城市中房价环比下降及涨幅回落城市个数均有所增加\r\n　　5月份，70个城市中新建商品住宅价格环比下降的城市有9个，比上月增加1个；涨幅回落的城市有26个，比上月增加3个。二手住宅价格环比下降的城市有7个，比上月增加2个；涨幅回落的城市有30个，比上月增加8个。\r\n\n相似原文:\n 　　新华社北京5月18日电国家统计局18日发布的数据显示，4月份，15个一线和热点二线城市新建商品住宅价格同比涨幅回落，9个城市环比下降或持平。\\n　　这9个价格环比下降或持平的城市是天津、上海、南京、合肥、福州、杭州、厦门、深圳、成都。\\n　　“4月份，因地制宜、因城施策的房地产调控政策继续发挥作用。”国家统计局城市司高级统计师刘建伟说，从同比看，15个城市新建商品住宅价格涨幅均比上月回落，回落幅度在0.7至7.4个百分点之间。从环比看，9个城市新建商品住宅价格下降或持平；5个城市涨幅回落，回落幅度在0.2至1.1个百分点之间。\\n　　国家统计局当天还发布了4月份70个大中城市住宅销售价格统计数据。刘建伟介绍，从同比看，4月份70个城市中有30个城市新建商品住宅价格涨幅比上月回落，比3月份增加6个，回落城市中23个为一二线城市。初步测算，一线城市新建商品住宅价格同比涨幅连续7个月回落，4月份比3月份回落2.8个百分点；二线城市新建商品住宅价格同比涨幅连续5个月回落，4月份比3月份回落1.0个百分点；三线城市新建商品住宅价格同比涨幅略有扩大，4月份比3月份扩大0.4个百分点。\\n　　从环比看，4月份70个城市中有23个城市新建商品住宅价格涨幅比上月回落，比3月份增加13个；7个城市由上月上涨转为持平或下降；3个城市降幅扩大。（完）\n编辑距离： 480\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# 加载停用词\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "with open('chinese_stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = [i[:-1] for i in file.readlines()]\n",
    "    \n",
    "# 数据加载\n",
    "news = pd.read_csv('sqlResult.csv', encoding='gb18030')\n",
    "\n",
    "# 处理缺失值\n",
    "print(news[news.content.isna()].head())\n",
    "news = news.dropna(subset=['content'])\n",
    "print(news.shape)\n",
    "\n",
    "# 分词\n",
    "def split_text(text):\n",
    "    text = text.replace(' ', '')\n",
    "    text = text.replace('\\n', '')\n",
    "    text2 = jieba.cut(text.strip())\n",
    "    result = ' '.join([w for w in text2 if w not in stopwords])\n",
    "    return result\n",
    "# print(news.iloc[0].content)\n",
    "# print(split_text(news.iloc[0].content))\n",
    "import pickle, os\n",
    "\n",
    "if not os.path.exists('corpus.pkl'):\n",
    "    corpus = list(map(split_text, [str(i) for i in news.content]))\n",
    "    print(corpus[0])\n",
    "    print(len(corpus))\n",
    "    print(corpus[0])\n",
    "    with open('corpus.pkl', 'wb') as file:\n",
    "        pickle.dump(corpus, file)\n",
    "else:\n",
    "    # 调用上一次的处理结果\n",
    "    with open('corpus.pkl', 'rb') as file:\n",
    "        corpus = pickle.load(file)\n",
    "\n",
    "# 计算 corpus 的 TF-IDF 矩阵\n",
    "countvectorizer = CountVectorizer(encoding='gb18030', min_df=0.015)\n",
    "tfidfTransformer = TfidfTransformer()\n",
    "countvector = countvectorizer.fit_transform(corpus)\n",
    "tfidf = tfidfTransformer.fit_transform(countvector)\n",
    "print(tfidf.shape)\n",
    "\n",
    "# 标记是否是自己的新闻\n",
    "label = list(map(lambda source: 1 if '新华' in str(source) else 0, news.content))\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# 数据切分\n",
    "X_train, X_test, y_train, t_test = train_test_split(tfidf.toarray(), label, test_size=0.3, random_state=33)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "# y_predict = clf.predict(X_test)\n",
    "prediction = clf.predict(tfidf.toarray())\n",
    "labels = np.array(label)\n",
    "compare_news_index = pd.DataFrame({'prediction': prediction, 'labels': labels})\n",
    "# 计算所有可疑文章的 index\n",
    "copy_news_index = compare_news_index[(compare_news_index['prediction'] == 1) & (compare_news_index['labels'] == 0)].index\n",
    "# 计算所有新华社文章的 index\n",
    "xinhuashe_news_index = compare_news_index[(compare_news_index['labels'] == 1)].index\n",
    "print('可疑文章数：' + str(len(copy_news_index)))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "scaled_array = normalizer.fit_transform(tfidf.toarray())\n",
    "\n",
    "if not os.path.exists('label.pkl'):\n",
    "    # 使用 KMeans 完成聚类\n",
    "    kmeans = KMeans(n_clusters=25)\n",
    "    k_labels = kmeans.fit_predict(scaled_array)\n",
    "    with open('label.pkl', 'wb') as file:\n",
    "        pickle.dump(k_labels, file)\n",
    "    print('k_labels.shape', k_labels.shape)\n",
    "else:\n",
    "    # 调用上一次的处理结果\n",
    "    with open('label.pkl', 'rb') as file:\n",
    "        k_labels = pickle.load(file)\n",
    "\n",
    "if not os.path.exists('id_class.pkl'):\n",
    "    # 创建一个 id_class\n",
    "    id_class = {index:class_ for index, class_ in enumerate(k_labels)}\n",
    "    with open('id_class.pkl', 'wb') as file:\n",
    "        pickle.dump(id_class, file)\n",
    "else:\n",
    "    # 调用上次的处理结果\n",
    "    with open('id_class.pkl', 'rb') as file:\n",
    "        id_class = pickle.load(file)\n",
    "\n",
    "\n",
    "if not os.path.exists('class_id.pkl'):\n",
    "    from collections import defaultdict\n",
    "    # 创建一个 class_id\n",
    "    class_id = defaultdict(set)\n",
    "    for index, class_ in id_class.items():\n",
    "        # 只统计新华社发布的 class_id\n",
    "        if index in xinhuashe_news_index.tolist(): \n",
    "            class_id[class_].add(index)\n",
    "    with open('class_id.pkl', 'wb') as file:\n",
    "        pickle.dump(class_id, file)\n",
    "else:\n",
    "    # 调用上次的处理结果\n",
    "    with open('class_id.pkl', 'rb') as file:\n",
    "        class_id = pickle.load(file)\n",
    "\n",
    "# 找出相似文本\n",
    "def find_similar_text(cpindex, top=10):\n",
    "    # 只在新华社发布的文章中进行查找\n",
    "    dist_dict = {i: cosine_similarity(tfidf[cpindex], tfidf[i]) for i in class_id[id_class[cpindex]]}\n",
    "    # 从大到小进行排序\n",
    "    return sorted(dist_dict.items(), key=lambda x: x[1][0], reverse=True)[:top]\n",
    "\n",
    "cpindex = 3352\n",
    "similar_list = find_similar_text(cpindex)\n",
    "print(similar_list)\n",
    "print('怀疑抄袭：\\n', news.iloc[cpindex].content)\n",
    "# 找一篇相似的原文\n",
    "similar2 = similar_list[0][0]\n",
    "print('相似原文:\\n', news.iloc[similar2].content)\n",
    "\n",
    "\n",
    "import editdistance\n",
    "# 看下两篇文章之间的编辑距离\n",
    "print('编辑距离：', editdistance.eval(corpus[cpindex], corpus[similar2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}